{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 美国波士顿地区房价数据描述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 从 sklearn.datasets 导入波士顿房价数据读取器\n",
    "from sklearn.datasets import load_boston\n",
    "# 从读取房价数据存储在变量boston中。\n",
    "boston=load_boston()\n",
    "# 输出数数据描述\n",
    "print boston.DESCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  美国波士顿地区房价数据分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max target value is 50.0\n",
      "The min target value is 5.0\n",
      "The average target value is 22.532806324110677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qhg/.conda/envs/py2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.cross_validation 导入数据分割器。\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# 导入numpy并重新命名为np\n",
    "import numpy as np\n",
    "\n",
    "X=boston.data\n",
    "y=boston.target\n",
    "\n",
    "# 随机取样25%的数据构建测试样本，其余作为训练样本\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, random_state=33, test_size=0.25)\n",
    "\n",
    "# 分析回归目标值得差异。\n",
    "print \"The max target value is\", np.max(boston.target)\n",
    "print \"The min target value is\", np.min(boston.target)\n",
    "print \"The average target value is\", np.mean(boston.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练与测试数据标准化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[33.8 20.3 10.2 22.  21.2 24.2 29.  22.7 21.8 34.9 25.2 20.9 19.4 20.\n 14.  30.1 33.1 20.6 22.6 33.4 20.1 10.5 15.6 16.8 22.6 34.6 19.8 17.8\n 22.  17.4 15.4 16.7 22.6 15.1 21.4 15.3  7.4 13.9 17.6 25.  46.7 17.1\n 23.1 18.7 21.9 18.9 26.7 22.3 25.  14.6 42.8 17.3 22.2 36.5 22.8 19.9\n 36.2 50.  25.  22.2 17.5 23.9 19.6 24.7 28.4  8.7 21.7 20.  19.9 24.5\n 15.   7.  15.2 20.4  8.5 17.1 30.1 15.  19.4 23.2 17.  18.9 50.  25.\n 46.   7.2 17.8 35.1 24.3  5.  16.6 21.8 28.5 22.  20.3 21.7 26.4 30.7\n 50.  17.2 26.6 21.  23.4 19.5 20.7 23.3 48.8 15.6 19.6 17.4 21.7 14.6\n 37.9  9.7 17.8 12.1 20.1 29.9 26.4 18.8 32.5 15.7 13.4 21.7 23.6 11.9\n 13.8 22.2 13.  33.2 50.  22.3 22.4 23.8 29.1 20.8 23.7 19.8 13.9 28.4\n 45.4 23.7 50.  18.  17.1 18.9 10.4 24.7 23.9 23.  20.2  8.5 14.2 20.3\n 18.5 12.  19.3 20.6 16.1 12.3 23.1 22.7 20.3 16.7 27.9 21.4  8.1 37.6\n 15.6 29.6 22.9 24.8 24.4 50.  28.7 50.  16.5 18.2 50.  16.2 14.1 21.2\n 18.4 25.  50.  21.2 20.4 15.2 22.  19.8 22.1 23.9 24.6 23.9 21.7 44.8\n  7.2 18.5 20.1 23.3 19.2 29.1 31.  22.9 27.5 39.8 22.  22.8 22.9 14.3\n 14.5 22.4 19.3 32.  20.1 18.3 24.5 18.4 23.1 22.6 20.2 17.8 31.6 43.5\n 36.4 11.3 20.5 23.2 29.8 20.6 24.3 18.1 19.1 21.4 31.5 19.2 14.3 24.8\n 21.1 18.2 48.3 19.4 21.2 10.9 27.5 34.7 14.4 22.8 17.8 50.  24.4 12.8\n 30.8 28.2 25.  33.1 27.5 12.7 43.1 13.4 21.5 33.4 23.8 21.  26.6 18.5\n 23.  24.1 20.5 32.2 14.4 11.8 19.5 23.7 13.2 29.  18.2 18.6 23.  42.3\n 17.2 16.2 20.  30.3 20.9 20.4 24.8 18.7 16.8 22.5 18.8 23.7 23.8 19.6\n 20.4 16.1 44.  19.3 17.4 10.2 11.7 37.2 11.  23.6 22.8 15.  34.9 17.9\n 24.4 24.5  6.3 29.4 10.4 38.7 20.  19.4 37.  50.  18.7 48.5 35.4 23.4\n  7.  50.  20.7 35.4  9.6 25.1 16.1 27.  16.6 13.3 25.  24.  19.6 29.6\n 21.7 19.1 22.  13.3 27.1 22.9 33.2 13.5 14.5  8.3 41.7 31.2 23.9 23.1\n 24.3 18.3 20.8 28.  19.5 21.5 13.1 12.5 31.7 13.1 23.1 14.5 22.2 13.1\n 37.3 22.  10.2  5.  19.3 16.  18.6 50.  31.6 24.1 15.6 19.4 23.3 23.2\n 13.6].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b446c538af65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mss_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mss_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mss_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mss_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qhg/.conda/envs/py2/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qhg/.conda/envs/py2/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qhg/.conda/envs/py2/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \"\"\"\n\u001b[1;32m    611\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[0;32m--> 612\u001b[0;31m                         warn_on_dtype=True, estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qhg/.conda/envs/py2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[33.8 20.3 10.2 22.  21.2 24.2 29.  22.7 21.8 34.9 25.2 20.9 19.4 20.\n 14.  30.1 33.1 20.6 22.6 33.4 20.1 10.5 15.6 16.8 22.6 34.6 19.8 17.8\n 22.  17.4 15.4 16.7 22.6 15.1 21.4 15.3  7.4 13.9 17.6 25.  46.7 17.1\n 23.1 18.7 21.9 18.9 26.7 22.3 25.  14.6 42.8 17.3 22.2 36.5 22.8 19.9\n 36.2 50.  25.  22.2 17.5 23.9 19.6 24.7 28.4  8.7 21.7 20.  19.9 24.5\n 15.   7.  15.2 20.4  8.5 17.1 30.1 15.  19.4 23.2 17.  18.9 50.  25.\n 46.   7.2 17.8 35.1 24.3  5.  16.6 21.8 28.5 22.  20.3 21.7 26.4 30.7\n 50.  17.2 26.6 21.  23.4 19.5 20.7 23.3 48.8 15.6 19.6 17.4 21.7 14.6\n 37.9  9.7 17.8 12.1 20.1 29.9 26.4 18.8 32.5 15.7 13.4 21.7 23.6 11.9\n 13.8 22.2 13.  33.2 50.  22.3 22.4 23.8 29.1 20.8 23.7 19.8 13.9 28.4\n 45.4 23.7 50.  18.  17.1 18.9 10.4 24.7 23.9 23.  20.2  8.5 14.2 20.3\n 18.5 12.  19.3 20.6 16.1 12.3 23.1 22.7 20.3 16.7 27.9 21.4  8.1 37.6\n 15.6 29.6 22.9 24.8 24.4 50.  28.7 50.  16.5 18.2 50.  16.2 14.1 21.2\n 18.4 25.  50.  21.2 20.4 15.2 22.  19.8 22.1 23.9 24.6 23.9 21.7 44.8\n  7.2 18.5 20.1 23.3 19.2 29.1 31.  22.9 27.5 39.8 22.  22.8 22.9 14.3\n 14.5 22.4 19.3 32.  20.1 18.3 24.5 18.4 23.1 22.6 20.2 17.8 31.6 43.5\n 36.4 11.3 20.5 23.2 29.8 20.6 24.3 18.1 19.1 21.4 31.5 19.2 14.3 24.8\n 21.1 18.2 48.3 19.4 21.2 10.9 27.5 34.7 14.4 22.8 17.8 50.  24.4 12.8\n 30.8 28.2 25.  33.1 27.5 12.7 43.1 13.4 21.5 33.4 23.8 21.  26.6 18.5\n 23.  24.1 20.5 32.2 14.4 11.8 19.5 23.7 13.2 29.  18.2 18.6 23.  42.3\n 17.2 16.2 20.  30.3 20.9 20.4 24.8 18.7 16.8 22.5 18.8 23.7 23.8 19.6\n 20.4 16.1 44.  19.3 17.4 10.2 11.7 37.2 11.  23.6 22.8 15.  34.9 17.9\n 24.4 24.5  6.3 29.4 10.4 38.7 20.  19.4 37.  50.  18.7 48.5 35.4 23.4\n  7.  50.  20.7 35.4  9.6 25.1 16.1 27.  16.6 13.3 25.  24.  19.6 29.6\n 21.7 19.1 22.  13.3 27.1 22.9 33.2 13.5 14.5  8.3 41.7 31.2 23.9 23.1\n 24.3 18.3 20.8 28.  19.5 21.5 13.1 12.5 31.7 13.1 23.1 14.5 22.2 13.1\n 37.3 22.  10.2  5.  19.3 16.  18.6 50.  31.6 24.1 15.6 19.4 23.3 23.2\n 13.6].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# 从 sklearn.preprocession 导入数据标准化模块\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 分别初始化对特征和目标值得标准化器。\n",
    "ss_X=StandardScaler()\n",
    "ss_y=StandardScaler()\n",
    "\n",
    "# 分别对训练和测试数据得特征以及目标值进行标准化处理\n",
    "X_train=ss_X.fit_transform(X_train)\n",
    "X_test=ss_X.transform(X_test)\n",
    "y_train=ss_y.fit_transform(y_train)\n",
    "y_test=ss_y.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
